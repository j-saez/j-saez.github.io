# Hello, I'm Javier

Welcome to my Github Pages site. Here's a bit about me:

## About me

Hello! I'm Javier, a passionate computer scientist and coder deeply enamored with the world of technology. I find joy in exploring the vast capabilities of programming, often navigating my coding adventures through the command line and optimizing my workflow with terminal-based tools. Neovim has become my coding haven, transformed into a personalized IDE with LSP, autocompletion, and debugging support.

My journey into the realms of computer vision and deep learning began during my bachelor's studies, where I marveled at the profound abilities of algorithms to perform complex tasks with remarkable speed. This fascination led me to focus my research on domain adaptation algorithms for robotics, addressing the challenges of manual data labeling. Continuing this trajectory into my master's, I published our findings in a conference, sparking my deep interest in research.

Currently pursuing a Ph.D., I'm immersed in the world of 3D perception fusion algorithms. Leveraging point clouds from LiDAR and RGB images, my goal is to unravel the intricacies of merging spatial data for a comprehensive understanding of the environment. Driven by relentless curiosity, I aspire to push the boundaries of technology and make meaningful contributions to its evolution.

Connect with me on [LinkedIn](https://www.linkedin.com/in/javier-saez-perez-93228324b/) or [YouTube](https://www.youtube.com/channel/UCkSx88YcYonJApPRn_VuK5Q) to join the conversation!

## Research Experience

### Openpilot Integration for Remote Driving
- **Researcher at UWS and Thales Glasgow (Part of the PhD)**
  *June 2021 – Feb. 2022*
  - Deployed a system leveraging Openpilot for remote driving of a Toyota Prius 2019.
  - Enabled remote control via 4G and 5G commercial networks, ensuring seamless connectivity.
  - Tools: Python, C++, Bash Scripting, PyTorch, GitHub.

### Fusion Algorithms for Off-road Vehicles
- **Researcher at UWS and Thales Glasgow (Part of the PhD)**
  *March 2022 - Present*
  - Conducted system calibration and learned data collection techniques for multi-sensor systems.
  - Created a comprehensive multi-sensor dataset for off-road scenarios.
  - Implemented and applied fusion algorithms to enhance perception in off-road environments.
  - Utilized tools: ROS, Python, C++, CMake, PyTorch, LiDAR, and RGB cameras.

### CO2 Emission Prediction for SAE Level 2 Autonomous Vehicles
- **Researcher at UWS and Thales Glasgow (Part of the PhD)**
  *April 2022 - July 2022*
  - Implemented a Vision Transformer architecture from scratch using PyTorch for predicting CO2 emissions in SAE Level 2 autonomous vehicles.
  - Collected a dedicated dataset using a Toyota Prius 2019 to train the algorithm.
  - Achieved a high \(R^2\) value of 0.982.
  - Submitted a publication detailing the research, currently under review.

### Lidar Resolution Enhancement
- **Researcher at UWS and Thales Glasgow (Part of the PhD)**
  *Sept. 2023 - Dec. 2023*
  - Addressed challenges related to low-resolution Lidar.
  - Enhanced fusion algorithms by implementing point cloud upsampling techniques with Graph Neural Networks and PointNet++, mitigating low-resolution Lidar challenges.
  - Submitted a publication on the upsampling techniques, currently under review.
  - Contributed insights and solutions to Thales Glasgow's efforts in overcoming Lidar resolution limitations.

## Education

- **BE (Hons) in Robotics Engineering**  
  *University of Alicante*, Alicante, Spain  
  *2016–2020*

- **MSc in Automatics and Robotics**  
  *University of Alicante*, Alicante, Spain  
  *2020–2021*

- **Ph.D. in 3D perception and machine learning**  
  *University of the West of Scotland*, *Paisley*  
  *2021–2025*

## Projects

### [Implementation of Famous Papers](https://github.com/j-saez/Pytorch-implementations)
- GANs: DCGAN ([repo](https://github.com/j-saez/dc_gan)), WGAN ([repo](https://github.com/j-saez/WGAN)), WGANGP ([repo](https://github.com/j-saez/WGAN_GP)), PixelDA ([repo](https://github.com/j-saez/PixelDA), [YouTube video](https://www.youtube.com/watch?v=PqOTBlbOxu8)), Pix2Pix ([repo](https://github.com/j-saez/pix2pix), [YouTube video](https://www.youtube.com/watch?v=gB1oNYpB2hk)), and CycleGAN ([repo](https://github.com/j-saez/cycle_gan)).
- Object detectors: YOLOv1 ([repo](https://github.com/j-saez/YOLOV1)), and YOLOv3 ([repo](https://github.com/j-saez/YOLOV3)).
- Point cloud classification and semantic segmentation models: PointNet ([repo](https://github.com/j-saez/pointnet)) and PointNet++ ([repo](https://github.com/j-saez/pointnet-plus-plus)).
- Vision Transformers: ViT ([repo](https://github.com/j-saez/vit)).
- Enabled distributed training using PyTorch Lightning and Distributed Data Parallelism (DDP).
- Dockerized the GitHub repositories for training, testing, and inference of the models.

